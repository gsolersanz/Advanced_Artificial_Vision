{"cells":[{"cell_type":"markdown","source":["# Pose landmark detection with MediaPipe\n","   \n","![alt text](https://developers.google.com/static/mediapipe/images/solutions/examples/pose_detector.png)\n","\n","[**MediaPipe**](https://developers.google.com/mediapipe) is a groundbreaking open-source framework developed by Google, designed to facilitate the building of advanced machine learning pipelines for processing media data, especially in the realms of audio, video, and graphics. What sets MediaPipe apart is its ability to provide a robust and efficient platform for developers and researchers to integrate cutting-edge machine learning models into their applications with relative ease and flexibility.\n","\n","At the heart of MediaPipe lies a collection of pre-built, customizable modules that address a variety of tasks common in media processing. These tasks range from object detection and tracking to facial landmark detection and pose estimation, all critical components in a myriad of applications such as augmented reality, gesture recognition, and interactive experiences (https://developers.google.com/mediapipe/solutions/examples).\n","\n","One of the key strengths of MediaPipe is its cross-platform capability. It is engineered to work seamlessly across different devices and platforms, making it highly versatile for a wide range of applications. Additionally, MediaPipe's real-time performance makes it ideal for interactive and live applications, where quick processing and low latency are crucial."],"metadata":{"id":"LiRHFvZX-H86"}},{"cell_type":"markdown","source":["## Install MediaPipe"],"metadata":{"id":"Ojd9KHOh_qR3"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ELghLQp1YvEt"},"outputs":[],"source":["!pip install mediapipe"]},{"cell_type":"markdown","source":["## Donwload video sample"],"metadata":{"id":"JCosR7CT_wEc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"Df0YfHX2Y-qW"},"outputs":[],"source":["!wget 'https://github.com/FranciscoFlorezRevuelta/HAR/raw/main/samples/S001C002P007R002A048_rgb.avi' -O example6.avi"]},{"cell_type":"markdown","source":["## Code"],"metadata":{"id":"G0DjKyfG_1Mb"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"uOLRku6UZH96"},"outputs":[],"source":["import cv2\n","import mediapipe as mp\n","import matplotlib.pyplot as plt\n","\n","# Initialize MediaPipe Pose model.\n","mp_pose = mp.solutions.pose\n","pose = mp_pose.Pose(static_image_mode=False, model_complexity=1, enable_segmentation=False, min_detection_confidence=0.5)\n","\n","# Initialize drawing utils\n","mp_drawing = mp.solutions.drawing_utils\n","\n","def process_frame(frame):\n","    \"\"\" Processes a single frame for pose detection and returns the annotated frame. \"\"\"\n","    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","    results = pose.process(frame_rgb)\n","    if results.pose_landmarks:\n","        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n","    return frame\n","\n","# Open video file\n","video_path = 'example6.avi'\n","cap = cv2.VideoCapture(video_path)\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","    frame = process_frame(frame)\n","    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n","    plt.show()\n","\n","cap.release()\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"183iBodp0Cc6Sq2AcFZgLe5rWBiQSYosj","timestamp":1742572411395}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}